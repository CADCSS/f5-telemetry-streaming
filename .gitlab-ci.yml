image: node:8

stages:
    - build
    - deploy
    - test
    - teardown
    - publish

build package:
    image: f5devcentral/containthedocs:rpmbuild
    stage: build
    script:
        - echo 'CI BUILD'
        # install packages first
        - npm run install-production
        - bash ./scripts/build_rpm.sh
    tags:
        - cm-official-docker-executor
    artifacts:
        name: f5-telemetry-$CI_BUILD_REF
        paths:
            - dist
        expire_in: 1 month

build docs:
    image: ${CONTAINTHEDOCS_IMAGE}
    stage: build
    script:
        - make html
        - vale --glob='*.{md,rst}' .
        #  - make linkcheck
    tags:
        - docker-executor
    artifacts:
        name: docs
        paths:
            - docs/_build/html
        expire_in: 1 month

# for this job following variables should be defined:
# CICD_AUTH_OS_USERNAME - VIO user
# CICD_AUTH_OS_PASSWORD - VIO password
# CICD_AUTH_OS_PROJECT  - VIO project
# or
# CICD_AUTH_OS_TOKEN - VIO auth token
# CICD_AUTH_OS_PROJECT - VIO project
# also one more variable should be defined
# CICD_PIPELINE_TRIGGER_FOR_DEPLOY - CI/CD trigger ID
#
# job triggers CI/CD trigger to initiate seperate pipeline for deployment
# this allows to parameterize pipeline to test packages against different
# versions of BIG-IP
trigger_deploy_job_14_1:
    stage: deploy
    tags:
        - docker-executor
    script:
        - curl -k -X POST -F token=${CICD_PIPELINE_TRIGGER_FOR_DEPLOY}
            -F ref=${CI_COMMIT_REF_NAME}
            -F "variables[REQ_DEVICE_PIPELINE]=true"
            -F "variables[REQ_PROJECT_NAME]=ts_cicd_bigip_14_1"
            -F "variables[REQ_BIGIP_VERSION]=14.1.0.1"
            -F "variables[REQ_BIGIP_BUILD]=0.0.7"
            ${CICD_PIPLINE_TRIGGER_URL}
    only:
        # run if scheduled
        - schedules

trigger_deploy_job_13_1:
    stage: deploy
    tags:
        - docker-executor
    script:
        - curl -k -X POST -F token=${CICD_PIPELINE_TRIGGER_FOR_DEPLOY}
            -F ref=${CI_COMMIT_REF_NAME}
            -F "variables[REQ_DEVICE_PIPELINE]=true"
            -F "variables[REQ_PROJECT_NAME]=ts_cicd_bigip_13_1"
            -F "variables[REQ_BIGIP_VERSION]=13.1.1.4"
            -F "variables[REQ_BIGIP_BUILD]=0.0.4"
            ${CICD_PIPLINE_TRIGGER_URL}
    only:
        # run if scheduled
        - schedules

deploy_bigip:
    stage: deploy
    tags:
    - cm-official-docker-executor
    image: ${CICD_CONTAINER_DEPLOY}
    variables:
        PROJECT_NAME: ${REQ_PROJECT_NAME}
        PROJECT_DIR: /root/deploy-projects/${REQ_PROJECT_NAME}
        BIGIP_VERSION: ${REQ_BIGIP_VERSION}
        BIGIP_BUILD: ${REQ_BIGIP_BUILD}
        BIGIP_BRANCH: ${REQ_BIGIP_BRANCH}
    artifacts:
        name: ${CI_COMMIT_REF_NAME}_bigip_${BIGIP_BRANCH}.${BIGIP_VERSION}.${BIGIP_BUILD}_harness_info
        paths:
        - ${CI_PROJECT_DIR}/harness_facts_flat.json
        when: on_success
    only:
        variables:
            - $REQ_DEVICE_PIPELINE == "true"
    script:
        - cd /root/cicd-bigip-deploy && make configure &&
            make printvars && cat ${PROJECT_DIR}/project-vars &&
            make setup && ls -als ${PROJECT_DIR} &&
            cp ${PROJECT_DIR}/harness_facts_flat.json ${CI_PROJECT_DIR}/harness_facts_flat.json

test package:
    stage: test
    script:
        # install jq
        - apt-get update
        - apt-get install -y jq
        # install node modules
        - npm run install-test
        # npm audit - install includes audit, but perform specific check and fail if needed
        - audit_report=$(npm audit --json)
        - echo $audit_report
        - actions=$(echo $audit_report | jq .actions | jq length)
        - if [ $actions -ne 0 ]; then echo 'ERROR! vulnerabilities exist'; exit 1; fi
        # linter
        - npm run lint
        # unit tests
        - npm run test && npm run report
    artifacts:
        name: ${CI_COMMIT_REF_NAME}_unittests_coverage
        paths:
            - coverage
    tags:
        - cm-official-docker-executor

test functional:
    stage: test
    script:
        - export TEST_HARNESS_FILE=${CI_PROJECT_DIR}/harness_facts_flat.json
        # really only need dev dependencies
        - npm run install-test
        - ls ./dist -ls
        - npm run test-functional
    tags:
        - cm-official-docker-executor
    only:
        variables:
            - $REQ_DEVICE_PIPELINE == "true"

teardown_bigip:
    stage: teardown
    tags:
        - cm-official-docker-executor
    image: ${CICD_CONTAINER_DEPLOY}
    variables:
        PROJECT_NAME: ${REQ_PROJECT_NAME}
        PROJECT_DIR: /root/deploy-projects/${REQ_PROJECT_NAME}
    script:
        - cd /root/cicd-bigip-deploy && make configure && make teardown
    when: always
    only:
        variables:
            - $REQ_DEVICE_PIPELINE == "true"

# Publish to internal artifactory
# Note: Will publish when new tags are pushed and use the current build in dist directory
# with the assumption being the rpm has been updated. However even if it hasn't the upload
# will simply update the existing rpm version/release in artifactory
publish rpm to artifactory:
    stage: publish
    only:
        - tags
    tags:
        - docker-executor
    script:
        # we do not want the new build (dist/new_build/*.rpm), we want the checked in build
        - RPM_FILE=$(ls dist/*.rpm)
        - RPM_NAME=$(basename $RPM_FILE)
        - URL=${ARTIFACTORY_BASE_URL}/f5-telemetry-streaming-rpm/${RPM_NAME}
        - echo ${URL}
        - >-
          UPLOAD_RESULT=$(curl -H "Authorization: Bearer ${ARTIFACTORY_TOKEN}" -X PUT --data-binary @${RPM_FILE} ${URL})
        - if [[ $? -eq 0 ]] && [[ "$UPLOAD_RESULT" == *created* ]]; then echo "Upload complete"; else echo "Upload failed"; exit 1; fi
        - echo $UPLOAD_RESULT

# Publish docs to internal pages
publish docs to pages:
    image: ${CONTAINTHEDOCS_IMAGE}
    stage: publish
    environment:
        name: staging
        url: https://${CI_PROJECT_NAMESPACE}.${PAGES_DOMAIN}/${CI_PROJECT_NAME}
    tags:
        - cm-official-docker-executor
    script:
        - mkdir -p ./public
        - cp -R docs/_build/html/* ./public
    artifacts:
        paths:
            - public
    only:
        - /^docs-.*$/

# Publish docs to clouddocs.f5networks.net
publish docs to staging:
    image: ${CONTAINTHEDOCS_IMAGE}
    stage: publish
    environment: 
        name: staging
        url: https://clouddocs.f5networks.net/products/extensions/f5-telemetry-streaming/latest
    tags:
        - cm-official-docker-executor
    only:
        - develop@cloudsolutions/f5-telemetry
    script:
        - aws s3 sync docs/_build/html s3://clouddocs.f5networks.net/products/extensions/f5-telemetry-streaming/latest
        # - aws s3 cp versions.json s3://clouddocs.f5networks.net/products/extensions/f5-telemetry-streaming/versions.json
        # create invalidation to clear cloudfront cache
        - aws cloudfront create-invalidation --distribution-id $AWS_DIST --paths /products/extensions/f5-telemetry-streaming/latest

# Publish docs to clouddocs.f5.com
publish docs to production:
    image: ${CONTAINTHEDOCS_IMAGE}
    stage: publish
    environment:
        name: production
        url: https://clouddocs.f5.com/products/extensions/f5-telemetry-streaming/latest
    only:
        # fill in desired release branch name to add deployment from a branch: currently *master*
        - master@cloudsolutions/f5-telemetry
        - docs-publish@cloudsolutions/f5-telemetry
    tags:
        - cm-official-docker-executor
    script:
        # Uncomment and set to create desired version format
        - aws s3 sync docs/_build/html s3://clouddocs.f5.com/products/extensions/f5-telemetry-streaming/latest
        # - aws s3 cp versions.json s3://clouddocs.f5.com/products/extensions/f5-telemetry-streaming/versions.json
        # create invalidation to clear cloudfront cache
        - aws cloudfront create-invalidation --distribution-id $AWS_DIST --paths /products/extensions/f5-telemetry-streaming/latest
