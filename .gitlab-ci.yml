image: node:8

stages:
    - build
    - deploy
    - test
    - teardown
    - publish

build_package:
    image: f5devcentral/containthedocs:rpmbuild
    stage: build
    script:
        - echo 'CI BUILD'
        # install packages first
        - npm run install-production
        - bash ./scripts/build_rpm.sh
    tags:
        - cm-official-docker-executor
    artifacts:
        name: f5-telemetry-$CI_BUILD_REF
        paths:
            - dist
        expire_in: 1 month

build_docs:
    image: ${CONTAINTHEDOCS_IMAGE}
    stage: build
    script:
        - make html
        - vale --glob='*.{md,rst}' .
        #  - make linkcheck
    tags:
        - docker-executor
    artifacts:
        name: docs
        paths:
            - docs/_build/html
        expire_in: 1 month

# for this job following variables should be defined:
# CICD_AUTH_OS_USERNAME - VIO user
# CICD_AUTH_OS_PASSWORD - VIO password
# CICD_AUTH_OS_PROJECT  - VIO project
# or
# CICD_AUTH_OS_TOKEN - VIO auth token
# CICD_AUTH_OS_PROJECT - VIO project
# also one more variable should be defined
# CICD_PIPELINE_TRIGGER_FOR_DEPLOY - CI/CD trigger ID
#
# job triggers CI/CD trigger to initiate seperate pipeline for deployment
# this allows to parameterize pipeline to test packages against different
# versions of BIG-IP
# trigger_deploy_job_14_1:
#     stage: deploy
#     tags:
#         - docker-executor
#     script:
#         - curl -k -X POST -F token=${CICD_PIPELINE_TRIGGER_FOR_DEPLOY}
#             -F ref=${CI_COMMIT_REF_NAME}
#             -F "variables[REQ_PROJECT_NAME]=ts_cicd_bigip_14_1"
#             -F "variables[REQ_TEST_DECLARATION]=declaration14.1.yml"
#             ${CICD_PIPLINE_TRIGGER_URL}
#     only:
#         # run if scheduled
#         - schedules

trigger_deploy_job_13_1:
    stage: deploy
    tags:
        - docker-executor
    script:
        - curl -k -X POST -F token=${CICD_PIPELINE_TRIGGER_FOR_DEPLOY}
            -F ref=${CI_COMMIT_REF_NAME}
            -F "variables[REQ_PROJECT_NAME]=ts_cicd_bigip_13_1"
            -F "variables[REQ_TEST_DECLARATION]=declaration13.1.yml"
            ${CICD_PIPLINE_TRIGGER_URL}
    only:
        # run if scheduled
        - schedules

deploy_bigip:
    stage: deploy
    tags:
        - cm-official-docker-executor
    image: ${CICD_CONTAINER_DEPLOY}
    variables:
        PROJECT_NAME: ${REQ_PROJECT_NAME}
        PROJECT_DECLARATION: ./test/deployment/${REQ_TEST_DECLARATION}
        PROJECT_DIR: /root/deploy-projects/${REQ_PROJECT_NAME}
        CUSTOM_DECLARATION: yes
    artifacts:
        name: ${CI_COMMIT_REF_NAME}_bigip.${REQ_TEST_DECLARATION}_harness_info
        paths:
            - ${CI_PROJECT_DIR}/harness_facts_flat.json
        when: on_success
    only:
        variables:
            - $REQ_DEVICE_PIPELINE == "true"
    script:
        - cd /root/cicd-bigip-deploy && make configure &&
            make printvars && cat ${PROJECT_DIR}/project-vars &&
            make setup && ls -als ${PROJECT_DIR} &&
            cp ${PROJECT_DIR}/harness_facts_flat.json ${CI_PROJECT_DIR}/harness_facts_flat.json

# test_package:
#     stage: test
#     script:
#         # install jq
#         - apt-get update
#         - apt-get install -y jq
#         # install node modules
#         - npm run install-test
#         # npm audit - install includes audit, but perform specific check and fail if needed
#         - audit_report=$(npm audit --json)
#         - echo $audit_report
#         - actions=$(echo $audit_report | jq .actions | jq length)
#         - if [ $actions -ne 0 ]; then echo 'ERROR! vulnerabilities exist'; exit 1; fi
#         # linter
#         - npm run lint
#         # unit tests
#         - npm run test && npm run report
#     artifacts:
#         name: ${CI_COMMIT_REF_NAME}_unittests_coverage
#         paths:
#             - coverage
#     tags:
#         - cm-official-docker-executor

# test_functional:
#     stage: test
#     script:
#         - export TEST_HARNESS_FILE=${CI_PROJECT_DIR}/harness_facts_flat.json
#         # really only need dev dependencies
#         - npm run install-test
#         - ls ./dist -ls
#         - npm run test-functional
#     # troubleshooting functional test failures typically requires looking at logs, one of which is
#     # the restnoded log that is captured by the functional tests.  This saves off the folder
#     # containing that log as an artifact to speed up the troubleshooting process
#     artifacts:
#         name: ${CI_COMMIT_REF_NAME}_functests_logs
#         paths:
#             - test/functional/logs
#         when: always
#     tags:
#         - cm-official-docker-executor
#     only:
#         variables:
#             - $REQ_DEVICE_PIPELINE == "true"

teardown_bigip:
    stage: teardown
    tags:
        - cm-official-docker-executor
    image: ${CICD_CONTAINER_DEPLOY}
    variables:
        PROJECT_NAME: ${REQ_PROJECT_NAME}
        PROJECT_DECLARATION: ./test/deployment/${REQ_TEST_DECLARATION}
        PROJECT_DIR: /root/deploy-projects/${REQ_PROJECT_NAME}
        CUSTOM_DECLARATION: yes
    script:
        - cd /root/cicd-bigip-deploy && make configure && make teardown
    when: always
    only:
        variables:
            - $REQ_DEVICE_PIPELINE == "true"

# Publish to internal artifactory
# Note: Will publish when new tags are pushed and use the current build in dist directory
# with the assumption being the rpm has been updated. However even if it hasn't the upload
# will simply update the existing rpm version/release in artifactory
publish_rpm_to_artifactory:
    stage: publish
    only:
        - tags
    tags:
        - docker-executor
    script:
        # we do not want the new build (dist/new_build/*.rpm), we want the checked in build
        - RPM_FILE=$(ls dist/*.rpm)
        - RPM_NAME=$(basename $RPM_FILE)
        - URL=${ARTIFACTORY_BASE_URL}/f5-telemetry-streaming-rpm/${RPM_NAME}
        - echo ${URL}
        - >-
          UPLOAD_RESULT=$(curl -H "Authorization: Bearer ${ARTIFACTORY_TOKEN}" -X PUT --data-binary @${RPM_FILE} ${URL})
        - if [[ $? -eq 0 ]] && [[ "$UPLOAD_RESULT" == *created* ]]; then echo "Upload complete"; else echo "Upload failed"; exit 1; fi
        - echo $UPLOAD_RESULT

# Publish docs to internal pages - note: this job name MUST be 'pages'
pages:
    image: ${CONTAINTHEDOCS_IMAGE}
    stage: publish
    environment:
        name: staging
        url: https://${CI_PROJECT_NAMESPACE}.${PAGES_DOMAIN}/${CI_PROJECT_NAME}
    tags:
        - cm-official-docker-executor
    script:
        - mkdir -p ./public
        - cp -R docs/_build/html/* ./public
    artifacts:
        paths:
            - public
    only:
        - /^docs-.*$/

# Publish docs to clouddocs.f5networks.net
publish_docs_to_staging:
    image: ${CONTAINTHEDOCS_IMAGE}
    stage: publish
    environment: 
        name: staging
        url: https://clouddocs.f5networks.net/products/extensions/f5-telemetry-streaming/latest
    tags:
        - cm-official-docker-executor
    only:
        - develop@cloudsolutions/f5-telemetry
    script:
        - aws s3 sync docs/_build/html s3://clouddocs.f5networks.net/products/extensions/f5-telemetry-streaming/latest
        # - aws s3 cp versions.json s3://clouddocs.f5networks.net/products/extensions/f5-telemetry-streaming/versions.json
        # create invalidation to clear cloudfront cache
        - aws cloudfront create-invalidation --distribution-id $AWS_DIST --paths /products/extensions/f5-telemetry-streaming/latest

# Publish docs to clouddocs.f5.com
publish_docs_to_production:
    image: ${CONTAINTHEDOCS_IMAGE}
    stage: publish
    environment:
        name: production
        url: https://clouddocs.f5.com/products/extensions/f5-telemetry-streaming/latest
    only:
        # fill in desired release branch name to add deployment from a branch: currently *master*
        - master@cloudsolutions/f5-telemetry
        - docs-publish@cloudsolutions/f5-telemetry
    tags:
        - cm-official-docker-executor
    script:
        # Uncomment and set to create desired version format
        - aws s3 sync docs/_build/html s3://clouddocs.f5.com/products/extensions/f5-telemetry-streaming/latest
        # - aws s3 cp versions.json s3://clouddocs.f5.com/products/extensions/f5-telemetry-streaming/versions.json
        # create invalidation to clear cloudfront cache
        - aws cloudfront create-invalidation --distribution-id $AWS_DIST --paths /products/extensions/f5-telemetry-streaming/latest
